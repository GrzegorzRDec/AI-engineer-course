{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression\n",
    "\n",
    "Dataset 50 startups\n",
    "\n",
    "Profit - **dependent** variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "dataset = pd.read_csv(\"50_startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzić poniższe:\n",
    "dataset.isnull()     # <- checking id there is a null\n",
    "dataset.isna().any()  # <-checking if there are null variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the dataset into X and Y \n",
    "X = dataset.iloc[:,:-1].values\n",
    "Y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer( transformers = [('encoder', OneHotEncoder(), [3] )], remainder = 'passthrough' )\n",
    "X = np.array( ct.fit_transform(X) )\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the data into training and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standarization:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,3:] = sc.fit_transform( X_train[ :, 3: ] ) # <-- omiting one hot coding columns\n",
    "X_test[:,3:] = sc.transform( X_test[ :, 3: ] ) # <-- only transform (we are keeping the fitted values)\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(2) #<-how many decimal places\n",
    "print( np.concatenate( ( y_pred.reshape( len( y_pred ), 1 ), y_test.reshape( len( y_test ), 1 ) ), 1 ) ) #concatenate \n",
    "    #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as me \n",
    "print( me( y_test, y_pred) ) #return deviation from actual values from predicted values \n",
    "                # as small deviation is as good the model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 value abd r2 adjusted\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_addC = sm.add_constant(X)\n",
    "result = sm.OLS(y,X_addC)\n",
    "print( result.rsquared, result.rsquared_adj )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or.....\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred) # <- return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# polynomial regression\n",
    "dataset: Position_salaries\n",
    "\n",
    "small dataset, so model is trained on all data, also trained on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Positon_Salaries.csv')\n",
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.ilos[:,1:-1].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures( degree = 4 ) # <- degree of the polynomial\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(regressor.predict([[6.5]]) #linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(lin_reg_2.predict(poly_reg.fit_transform([[6.5]])) #polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification algorythms\n",
    "\n",
    "**Logistic regression** - applied, when data is grouped\n",
    "\n",
    "dataset: Social_Network_Ads.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  Purchased\n",
       "0     19            19000          0\n",
       "1     35            20000          0\n",
       "2     26            43000          0\n",
       "3     27            57000          0\n",
       "4     19            76000          0\n",
       "..   ...              ...        ...\n",
       "395   46            41000          1\n",
       "396   51            23000          1\n",
       "397   50            20000          1\n",
       "398   36            33000          0\n",
       "399   49            36000          1\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.90e+01, 1.90e+04],\n",
       "       [3.50e+01, 2.00e+04],\n",
       "       [2.60e+01, 4.30e+04],\n",
       "       [2.70e+01, 5.70e+04],\n",
       "       [1.90e+01, 7.60e+04],\n",
       "       [2.70e+01, 5.80e+04],\n",
       "       [2.70e+01, 8.40e+04],\n",
       "       [3.20e+01, 1.50e+05],\n",
       "       [2.50e+01, 3.30e+04],\n",
       "       [3.50e+01, 6.50e+04],\n",
       "       [2.60e+01, 8.00e+04],\n",
       "       [2.60e+01, 5.20e+04],\n",
       "       [2.00e+01, 8.60e+04],\n",
       "       [3.20e+01, 1.80e+04],\n",
       "       [1.80e+01, 8.20e+04],\n",
       "       [2.90e+01, 8.00e+04],\n",
       "       [4.70e+01, 2.50e+04],\n",
       "       [4.50e+01, 2.60e+04],\n",
       "       [4.60e+01, 2.80e+04],\n",
       "       [4.80e+01, 2.90e+04],\n",
       "       [4.50e+01, 2.20e+04],\n",
       "       [4.70e+01, 4.90e+04],\n",
       "       [4.80e+01, 4.10e+04],\n",
       "       [4.50e+01, 2.20e+04],\n",
       "       [4.60e+01, 2.30e+04],\n",
       "       [4.70e+01, 2.00e+04],\n",
       "       [4.90e+01, 2.80e+04],\n",
       "       [4.70e+01, 3.00e+04],\n",
       "       [2.90e+01, 4.30e+04],\n",
       "       [3.10e+01, 1.80e+04],\n",
       "       [3.10e+01, 7.40e+04],\n",
       "       [2.70e+01, 1.37e+05],\n",
       "       [2.10e+01, 1.60e+04],\n",
       "       [2.80e+01, 4.40e+04],\n",
       "       [2.70e+01, 9.00e+04],\n",
       "       [3.50e+01, 2.70e+04],\n",
       "       [3.30e+01, 2.80e+04],\n",
       "       [3.00e+01, 4.90e+04],\n",
       "       [2.60e+01, 7.20e+04],\n",
       "       [2.70e+01, 3.10e+04],\n",
       "       [2.70e+01, 1.70e+04],\n",
       "       [3.30e+01, 5.10e+04],\n",
       "       [3.50e+01, 1.08e+05],\n",
       "       [3.00e+01, 1.50e+04],\n",
       "       [2.80e+01, 8.40e+04],\n",
       "       [2.30e+01, 2.00e+04],\n",
       "       [2.50e+01, 7.90e+04],\n",
       "       [2.70e+01, 5.40e+04],\n",
       "       [3.00e+01, 1.35e+05],\n",
       "       [3.10e+01, 8.90e+04],\n",
       "       [2.40e+01, 3.20e+04],\n",
       "       [1.80e+01, 4.40e+04],\n",
       "       [2.90e+01, 8.30e+04],\n",
       "       [3.50e+01, 2.30e+04],\n",
       "       [2.70e+01, 5.80e+04],\n",
       "       [2.40e+01, 5.50e+04],\n",
       "       [2.30e+01, 4.80e+04],\n",
       "       [2.80e+01, 7.90e+04],\n",
       "       [2.20e+01, 1.80e+04],\n",
       "       [3.20e+01, 1.17e+05],\n",
       "       [2.70e+01, 2.00e+04],\n",
       "       [2.50e+01, 8.70e+04],\n",
       "       [2.30e+01, 6.60e+04],\n",
       "       [3.20e+01, 1.20e+05],\n",
       "       [5.90e+01, 8.30e+04],\n",
       "       [2.40e+01, 5.80e+04],\n",
       "       [2.40e+01, 1.90e+04],\n",
       "       [2.30e+01, 8.20e+04],\n",
       "       [2.20e+01, 6.30e+04],\n",
       "       [3.10e+01, 6.80e+04],\n",
       "       [2.50e+01, 8.00e+04],\n",
       "       [2.40e+01, 2.70e+04],\n",
       "       [2.00e+01, 2.30e+04],\n",
       "       [3.30e+01, 1.13e+05],\n",
       "       [3.20e+01, 1.80e+04],\n",
       "       [3.40e+01, 1.12e+05],\n",
       "       [1.80e+01, 5.20e+04],\n",
       "       [2.20e+01, 2.70e+04],\n",
       "       [2.80e+01, 8.70e+04],\n",
       "       [2.60e+01, 1.70e+04],\n",
       "       [3.00e+01, 8.00e+04],\n",
       "       [3.90e+01, 4.20e+04],\n",
       "       [2.00e+01, 4.90e+04],\n",
       "       [3.50e+01, 8.80e+04],\n",
       "       [3.00e+01, 6.20e+04],\n",
       "       [3.10e+01, 1.18e+05],\n",
       "       [2.40e+01, 5.50e+04],\n",
       "       [2.80e+01, 8.50e+04],\n",
       "       [2.60e+01, 8.10e+04],\n",
       "       [3.50e+01, 5.00e+04],\n",
       "       [2.20e+01, 8.10e+04],\n",
       "       [3.00e+01, 1.16e+05],\n",
       "       [2.60e+01, 1.50e+04],\n",
       "       [2.90e+01, 2.80e+04],\n",
       "       [2.90e+01, 8.30e+04],\n",
       "       [3.50e+01, 4.40e+04],\n",
       "       [3.50e+01, 2.50e+04],\n",
       "       [2.80e+01, 1.23e+05],\n",
       "       [3.50e+01, 7.30e+04],\n",
       "       [2.80e+01, 3.70e+04],\n",
       "       [2.70e+01, 8.80e+04],\n",
       "       [2.80e+01, 5.90e+04],\n",
       "       [3.20e+01, 8.60e+04],\n",
       "       [3.30e+01, 1.49e+05],\n",
       "       [1.90e+01, 2.10e+04],\n",
       "       [2.10e+01, 7.20e+04],\n",
       "       [2.60e+01, 3.50e+04],\n",
       "       [2.70e+01, 8.90e+04],\n",
       "       [2.60e+01, 8.60e+04],\n",
       "       [3.80e+01, 8.00e+04],\n",
       "       [3.90e+01, 7.10e+04],\n",
       "       [3.70e+01, 7.10e+04],\n",
       "       [3.80e+01, 6.10e+04],\n",
       "       [3.70e+01, 5.50e+04],\n",
       "       [4.20e+01, 8.00e+04],\n",
       "       [4.00e+01, 5.70e+04],\n",
       "       [3.50e+01, 7.50e+04],\n",
       "       [3.60e+01, 5.20e+04],\n",
       "       [4.00e+01, 5.90e+04],\n",
       "       [4.10e+01, 5.90e+04],\n",
       "       [3.60e+01, 7.50e+04],\n",
       "       [3.70e+01, 7.20e+04],\n",
       "       [4.00e+01, 7.50e+04],\n",
       "       [3.50e+01, 5.30e+04],\n",
       "       [4.10e+01, 5.10e+04],\n",
       "       [3.90e+01, 6.10e+04],\n",
       "       [4.20e+01, 6.50e+04],\n",
       "       [2.60e+01, 3.20e+04],\n",
       "       [3.00e+01, 1.70e+04],\n",
       "       [2.60e+01, 8.40e+04],\n",
       "       [3.10e+01, 5.80e+04],\n",
       "       [3.30e+01, 3.10e+04],\n",
       "       [3.00e+01, 8.70e+04],\n",
       "       [2.10e+01, 6.80e+04],\n",
       "       [2.80e+01, 5.50e+04],\n",
       "       [2.30e+01, 6.30e+04],\n",
       "       [2.00e+01, 8.20e+04],\n",
       "       [3.00e+01, 1.07e+05],\n",
       "       [2.80e+01, 5.90e+04],\n",
       "       [1.90e+01, 2.50e+04],\n",
       "       [1.90e+01, 8.50e+04],\n",
       "       [1.80e+01, 6.80e+04],\n",
       "       [3.50e+01, 5.90e+04],\n",
       "       [3.00e+01, 8.90e+04],\n",
       "       [3.40e+01, 2.50e+04],\n",
       "       [2.40e+01, 8.90e+04],\n",
       "       [2.70e+01, 9.60e+04],\n",
       "       [4.10e+01, 3.00e+04],\n",
       "       [2.90e+01, 6.10e+04],\n",
       "       [2.00e+01, 7.40e+04],\n",
       "       [2.60e+01, 1.50e+04],\n",
       "       [4.10e+01, 4.50e+04],\n",
       "       [3.10e+01, 7.60e+04],\n",
       "       [3.60e+01, 5.00e+04],\n",
       "       [4.00e+01, 4.70e+04],\n",
       "       [3.10e+01, 1.50e+04],\n",
       "       [4.60e+01, 5.90e+04],\n",
       "       [2.90e+01, 7.50e+04],\n",
       "       [2.60e+01, 3.00e+04],\n",
       "       [3.20e+01, 1.35e+05],\n",
       "       [3.20e+01, 1.00e+05],\n",
       "       [2.50e+01, 9.00e+04],\n",
       "       [3.70e+01, 3.30e+04],\n",
       "       [3.50e+01, 3.80e+04],\n",
       "       [3.30e+01, 6.90e+04],\n",
       "       [1.80e+01, 8.60e+04],\n",
       "       [2.20e+01, 5.50e+04],\n",
       "       [3.50e+01, 7.10e+04],\n",
       "       [2.90e+01, 1.48e+05],\n",
       "       [2.90e+01, 4.70e+04],\n",
       "       [2.10e+01, 8.80e+04],\n",
       "       [3.40e+01, 1.15e+05],\n",
       "       [2.60e+01, 1.18e+05],\n",
       "       [3.40e+01, 4.30e+04],\n",
       "       [3.40e+01, 7.20e+04],\n",
       "       [2.30e+01, 2.80e+04],\n",
       "       [3.50e+01, 4.70e+04],\n",
       "       [2.50e+01, 2.20e+04],\n",
       "       [2.40e+01, 2.30e+04],\n",
       "       [3.10e+01, 3.40e+04],\n",
       "       [2.60e+01, 1.60e+04],\n",
       "       [3.10e+01, 7.10e+04],\n",
       "       [3.20e+01, 1.17e+05],\n",
       "       [3.30e+01, 4.30e+04],\n",
       "       [3.30e+01, 6.00e+04],\n",
       "       [3.10e+01, 6.60e+04],\n",
       "       [2.00e+01, 8.20e+04],\n",
       "       [3.30e+01, 4.10e+04],\n",
       "       [3.50e+01, 7.20e+04],\n",
       "       [2.80e+01, 3.20e+04],\n",
       "       [2.40e+01, 8.40e+04],\n",
       "       [1.90e+01, 2.60e+04],\n",
       "       [2.90e+01, 4.30e+04],\n",
       "       [1.90e+01, 7.00e+04],\n",
       "       [2.80e+01, 8.90e+04],\n",
       "       [3.40e+01, 4.30e+04],\n",
       "       [3.00e+01, 7.90e+04],\n",
       "       [2.00e+01, 3.60e+04],\n",
       "       [2.60e+01, 8.00e+04],\n",
       "       [3.50e+01, 2.20e+04],\n",
       "       [3.50e+01, 3.90e+04],\n",
       "       [4.90e+01, 7.40e+04],\n",
       "       [3.90e+01, 1.34e+05],\n",
       "       [4.10e+01, 7.10e+04],\n",
       "       [5.80e+01, 1.01e+05],\n",
       "       [4.70e+01, 4.70e+04],\n",
       "       [5.50e+01, 1.30e+05],\n",
       "       [5.20e+01, 1.14e+05],\n",
       "       [4.00e+01, 1.42e+05],\n",
       "       [4.60e+01, 2.20e+04],\n",
       "       [4.80e+01, 9.60e+04],\n",
       "       [5.20e+01, 1.50e+05],\n",
       "       [5.90e+01, 4.20e+04],\n",
       "       [3.50e+01, 5.80e+04],\n",
       "       [4.70e+01, 4.30e+04],\n",
       "       [6.00e+01, 1.08e+05],\n",
       "       [4.90e+01, 6.50e+04],\n",
       "       [4.00e+01, 7.80e+04],\n",
       "       [4.60e+01, 9.60e+04],\n",
       "       [5.90e+01, 1.43e+05],\n",
       "       [4.10e+01, 8.00e+04],\n",
       "       [3.50e+01, 9.10e+04],\n",
       "       [3.70e+01, 1.44e+05],\n",
       "       [6.00e+01, 1.02e+05],\n",
       "       [3.50e+01, 6.00e+04],\n",
       "       [3.70e+01, 5.30e+04],\n",
       "       [3.60e+01, 1.26e+05],\n",
       "       [5.60e+01, 1.33e+05],\n",
       "       [4.00e+01, 7.20e+04],\n",
       "       [4.20e+01, 8.00e+04],\n",
       "       [3.50e+01, 1.47e+05],\n",
       "       [3.90e+01, 4.20e+04],\n",
       "       [4.00e+01, 1.07e+05],\n",
       "       [4.90e+01, 8.60e+04],\n",
       "       [3.80e+01, 1.12e+05],\n",
       "       [4.60e+01, 7.90e+04],\n",
       "       [4.00e+01, 5.70e+04],\n",
       "       [3.70e+01, 8.00e+04],\n",
       "       [4.60e+01, 8.20e+04],\n",
       "       [5.30e+01, 1.43e+05],\n",
       "       [4.20e+01, 1.49e+05],\n",
       "       [3.80e+01, 5.90e+04],\n",
       "       [5.00e+01, 8.80e+04],\n",
       "       [5.60e+01, 1.04e+05],\n",
       "       [4.10e+01, 7.20e+04],\n",
       "       [5.10e+01, 1.46e+05],\n",
       "       [3.50e+01, 5.00e+04],\n",
       "       [5.70e+01, 1.22e+05],\n",
       "       [4.10e+01, 5.20e+04],\n",
       "       [3.50e+01, 9.70e+04],\n",
       "       [4.40e+01, 3.90e+04],\n",
       "       [3.70e+01, 5.20e+04],\n",
       "       [4.80e+01, 1.34e+05],\n",
       "       [3.70e+01, 1.46e+05],\n",
       "       [5.00e+01, 4.40e+04],\n",
       "       [5.20e+01, 9.00e+04],\n",
       "       [4.10e+01, 7.20e+04],\n",
       "       [4.00e+01, 5.70e+04],\n",
       "       [5.80e+01, 9.50e+04],\n",
       "       [4.50e+01, 1.31e+05],\n",
       "       [3.50e+01, 7.70e+04],\n",
       "       [3.60e+01, 1.44e+05],\n",
       "       [5.50e+01, 1.25e+05],\n",
       "       [3.50e+01, 7.20e+04],\n",
       "       [4.80e+01, 9.00e+04],\n",
       "       [4.20e+01, 1.08e+05],\n",
       "       [4.00e+01, 7.50e+04],\n",
       "       [3.70e+01, 7.40e+04],\n",
       "       [4.70e+01, 1.44e+05],\n",
       "       [4.00e+01, 6.10e+04],\n",
       "       [4.30e+01, 1.33e+05],\n",
       "       [5.90e+01, 7.60e+04],\n",
       "       [6.00e+01, 4.20e+04],\n",
       "       [3.90e+01, 1.06e+05],\n",
       "       [5.70e+01, 2.60e+04],\n",
       "       [5.70e+01, 7.40e+04],\n",
       "       [3.80e+01, 7.10e+04],\n",
       "       [4.90e+01, 8.80e+04],\n",
       "       [5.20e+01, 3.80e+04],\n",
       "       [5.00e+01, 3.60e+04],\n",
       "       [5.90e+01, 8.80e+04],\n",
       "       [3.50e+01, 6.10e+04],\n",
       "       [3.70e+01, 7.00e+04],\n",
       "       [5.20e+01, 2.10e+04],\n",
       "       [4.80e+01, 1.41e+05],\n",
       "       [3.70e+01, 9.30e+04],\n",
       "       [3.70e+01, 6.20e+04],\n",
       "       [4.80e+01, 1.38e+05],\n",
       "       [4.10e+01, 7.90e+04],\n",
       "       [3.70e+01, 7.80e+04],\n",
       "       [3.90e+01, 1.34e+05],\n",
       "       [4.90e+01, 8.90e+04],\n",
       "       [5.50e+01, 3.90e+04],\n",
       "       [3.70e+01, 7.70e+04],\n",
       "       [3.50e+01, 5.70e+04],\n",
       "       [3.60e+01, 6.30e+04],\n",
       "       [4.20e+01, 7.30e+04],\n",
       "       [4.30e+01, 1.12e+05],\n",
       "       [4.50e+01, 7.90e+04],\n",
       "       [4.60e+01, 1.17e+05],\n",
       "       [5.80e+01, 3.80e+04],\n",
       "       [4.80e+01, 7.40e+04],\n",
       "       [3.70e+01, 1.37e+05],\n",
       "       [3.70e+01, 7.90e+04],\n",
       "       [4.00e+01, 6.00e+04],\n",
       "       [4.20e+01, 5.40e+04],\n",
       "       [5.10e+01, 1.34e+05],\n",
       "       [4.70e+01, 1.13e+05],\n",
       "       [3.60e+01, 1.25e+05],\n",
       "       [3.80e+01, 5.00e+04],\n",
       "       [4.20e+01, 7.00e+04],\n",
       "       [3.90e+01, 9.60e+04],\n",
       "       [3.80e+01, 5.00e+04],\n",
       "       [4.90e+01, 1.41e+05],\n",
       "       [3.90e+01, 7.90e+04],\n",
       "       [3.90e+01, 7.50e+04],\n",
       "       [5.40e+01, 1.04e+05],\n",
       "       [3.50e+01, 5.50e+04],\n",
       "       [4.50e+01, 3.20e+04],\n",
       "       [3.60e+01, 6.00e+04],\n",
       "       [5.20e+01, 1.38e+05],\n",
       "       [5.30e+01, 8.20e+04],\n",
       "       [4.10e+01, 5.20e+04],\n",
       "       [4.80e+01, 3.00e+04],\n",
       "       [4.80e+01, 1.31e+05],\n",
       "       [4.10e+01, 6.00e+04],\n",
       "       [4.10e+01, 7.20e+04],\n",
       "       [4.20e+01, 7.50e+04],\n",
       "       [3.60e+01, 1.18e+05],\n",
       "       [4.70e+01, 1.07e+05],\n",
       "       [3.80e+01, 5.10e+04],\n",
       "       [4.80e+01, 1.19e+05],\n",
       "       [4.20e+01, 6.50e+04],\n",
       "       [4.00e+01, 6.50e+04],\n",
       "       [5.70e+01, 6.00e+04],\n",
       "       [3.60e+01, 5.40e+04],\n",
       "       [5.80e+01, 1.44e+05],\n",
       "       [3.50e+01, 7.90e+04],\n",
       "       [3.80e+01, 5.50e+04],\n",
       "       [3.90e+01, 1.22e+05],\n",
       "       [5.30e+01, 1.04e+05],\n",
       "       [3.50e+01, 7.50e+04],\n",
       "       [3.80e+01, 6.50e+04],\n",
       "       [4.70e+01, 5.10e+04],\n",
       "       [4.70e+01, 1.05e+05],\n",
       "       [4.10e+01, 6.30e+04],\n",
       "       [5.30e+01, 7.20e+04],\n",
       "       [5.40e+01, 1.08e+05],\n",
       "       [3.90e+01, 7.70e+04],\n",
       "       [3.80e+01, 6.10e+04],\n",
       "       [3.80e+01, 1.13e+05],\n",
       "       [3.70e+01, 7.50e+04],\n",
       "       [4.20e+01, 9.00e+04],\n",
       "       [3.70e+01, 5.70e+04],\n",
       "       [3.60e+01, 9.90e+04],\n",
       "       [6.00e+01, 3.40e+04],\n",
       "       [5.40e+01, 7.00e+04],\n",
       "       [4.10e+01, 7.20e+04],\n",
       "       [4.00e+01, 7.10e+04],\n",
       "       [4.20e+01, 5.40e+04],\n",
       "       [4.30e+01, 1.29e+05],\n",
       "       [5.30e+01, 3.40e+04],\n",
       "       [4.70e+01, 5.00e+04],\n",
       "       [4.20e+01, 7.90e+04],\n",
       "       [4.20e+01, 1.04e+05],\n",
       "       [5.90e+01, 2.90e+04],\n",
       "       [5.80e+01, 4.70e+04],\n",
       "       [4.60e+01, 8.80e+04],\n",
       "       [3.80e+01, 7.10e+04],\n",
       "       [5.40e+01, 2.60e+04],\n",
       "       [6.00e+01, 4.60e+04],\n",
       "       [6.00e+01, 8.30e+04],\n",
       "       [3.90e+01, 7.30e+04],\n",
       "       [5.90e+01, 1.30e+05],\n",
       "       [3.70e+01, 8.00e+04],\n",
       "       [4.60e+01, 3.20e+04],\n",
       "       [4.60e+01, 7.40e+04],\n",
       "       [4.20e+01, 5.30e+04],\n",
       "       [4.10e+01, 8.70e+04],\n",
       "       [5.80e+01, 2.30e+04],\n",
       "       [4.20e+01, 6.40e+04],\n",
       "       [4.80e+01, 3.30e+04],\n",
       "       [4.40e+01, 1.39e+05],\n",
       "       [4.90e+01, 2.80e+04],\n",
       "       [5.70e+01, 3.30e+04],\n",
       "       [5.60e+01, 6.00e+04],\n",
       "       [4.90e+01, 3.90e+04],\n",
       "       [3.90e+01, 7.10e+04],\n",
       "       [4.70e+01, 3.40e+04],\n",
       "       [4.80e+01, 3.50e+04],\n",
       "       [4.80e+01, 3.30e+04],\n",
       "       [4.70e+01, 2.30e+04],\n",
       "       [4.50e+01, 4.50e+04],\n",
       "       [6.00e+01, 4.20e+04],\n",
       "       [3.90e+01, 5.90e+04],\n",
       "       [4.60e+01, 4.10e+04],\n",
       "       [5.10e+01, 2.30e+04],\n",
       "       [5.00e+01, 2.00e+04],\n",
       "       [3.60e+01, 3.30e+04],\n",
       "       [4.90e+01, 3.60e+04]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer( missing_values=np.nan, strategy='mean' )\n",
    "imputer.fit( X )\n",
    "X = imputer.transform( X )\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the next:\n",
    "# - confusion matrix\n",
    "# - classification and clustering problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zaaplikować do do klasyfikacji z tego zadania\n",
    "\n",
    "#confision matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix( y_test, y_pred )\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
